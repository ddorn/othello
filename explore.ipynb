{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of OthelloGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "# os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "from functools import partial\n",
    "from typing import Tuple, Union, Dict\n",
    "\n",
    "from circuitsvis.attention import attention_patterns\n",
    "import einops\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch as t\n",
    "import transformer_lens.utils as utils\n",
    "import wandb\n",
    "from jaxtyping import Float, Int\n",
    "from neel_plotly import line\n",
    "from torch import Tensor\n",
    "from transformer_lens import (\n",
    "    HookedTransformer,\n",
    ")\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "from plotly_utils import imshow\n",
    "\n",
    "import utils as u\n",
    "from utils import *\n",
    "from plotting import *\n",
    "from probes import get_probe, get_neels_probe, ProbeTrainingArgs, LitLinearProbe\n",
    "\n",
    "from othello_world.mechanistic_interpretability.mech_interp_othello_utils import (\n",
    "    plot_single_board, )\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Things that you probably always want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_grad_enabled(False)\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg, model = get_othello_gpt(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tokens, val_valid = generate_training_data(1000, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Loading sample data\n",
    "full_games_tokens, full_games_board_index = load_sample_games()\n",
    "num_games = 50\n",
    "focus_games_tokens = full_games_tokens[:num_games]\n",
    "focus_games_board_index = full_games_board_index[:num_games]\n",
    "assert (TOKENS_TO_BOARD[focus_games_tokens] == focus_games_board_index).all()\n",
    "\n",
    "focus_states = move_sequence_to_state(focus_games_board_index)\n",
    "focus_valid_moves = move_sequence_to_state(focus_games_board_index, mode=\"valid\")\n",
    "\n",
    "print(\"focus states:\", focus_states.shape)\n",
    "print(\"focus_valid_moves\", focus_valid_moves.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = ModelMetricPlotter(val_tokens, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.plot_loss_per_move(True)\n",
    "model_metrics.plot_loss_per_move()\n",
    "model_metrics.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_game(\n",
    "    tokens: Int[Tensor, 'move'],\n",
    "    model: HookedTransformer,\n",
    "    move: int = None,\n",
    "    # Extra args\n",
    "    extra_boards: Optional[Dict[str, Tensor]] = None,\n",
    ") -> None:\n",
    "    if isinstance(tokens, list):\n",
    "        tokens = t.tensor(tokens, dtype=t.long)\n",
    "    if move is None:\n",
    "        move = tokens.shape[0] - 1\n",
    "    move = move % tokens.shape[0]\n",
    "    if extra_boards is None:\n",
    "        extra_boards = {}\n",
    "        \n",
    "    tokens = tokens[None, :move+1].to(model.cfg.device)\n",
    "    board_indices = tokens_to_board(tokens)\n",
    "\n",
    "    logits = model(tokens)\n",
    "\n",
    "    scale = logits.abs().max().item() * 0.5\n",
    "    predictions = logits_to_board(logits, 'log_prob')\n",
    "    state = move_sequence_to_state(board_indices, 'mine-their') * scale\n",
    "    valid = move_sequence_to_state(board_indices, mode=\"valid\") * scale\n",
    "\n",
    "    # Scale extra boards if they are boolean\n",
    "    for k, v in extra_boards.items():\n",
    "        if v.dtype == t.bool:\n",
    "            extra_boards[k] = v * scale\n",
    "\n",
    "    # Plotting\n",
    "    boards = t.stack([\n",
    "        state[0, -1],\n",
    "        valid[0, -1],\n",
    "        predictions[0, -1],\n",
    "        *extra_boards.values(),\n",
    "    ], dim=0)\n",
    "    plot_square_as_board(\n",
    "        boards,\n",
    "        facet_col=0,\n",
    "        facet_col_wrap=3 if len(boards) != 4 else 2,\n",
    "        facet_labels=[\"State before\", \"Valid moves\", \"Model logits\", *extra_boards.keys()],\n",
    "        title=f\"Game after {to_board_label(board_indices[0, -1].item())} - blue to play - move {move}\",\n",
    "    )\n",
    "\n",
    "\n",
    "explain_game([20, 19], model)\n",
    "explain_game(val_tokens[3], model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@t.inference_mode()\n",
    "def find_fail_datapoints(\n",
    "    model: HookedTransformer,\n",
    "    tokens: Int[Tensor, 'game move'],\n",
    "    threshold: float = 3,\n",
    "    nb_examples: int = 10,\n",
    "    biggest_mistakes: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Find datapoints where the model fails to predict the valid moves.\n",
    "\n",
    "    Plots the board for each datapoint where the model fails to predict the valid moves.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the probabilities for each cell\n",
    "    tokens = tokens[:, :59].to(model.cfg.device)\n",
    "    logits = model(tokens[:, :59])\n",
    "    probabilities = logits_to_board(logits, 'prob')  # [game, move, row, col]\n",
    "\n",
    "    # Compute the number of valid moves\n",
    "    valid_moves = move_sequence_to_state(tokens_to_board(tokens), mode=\"valid\")[:, :59]\n",
    "    nb_valid_moves = valid_moves.sum(dim=(-1, -2), keepdim=True)  # [game, move, 1, 1]\n",
    "\n",
    "    # Find which moves are considered correct\n",
    "    if biggest_mistakes:\n",
    "        error = t.zeros_like(probabilities)\n",
    "        error[valid_moves] = 1 - (probabilities * nb_valid_moves)[valid_moves]\n",
    "        error[~valid_moves] = (probabilities * nb_valid_moves)[~valid_moves]\n",
    "        error = error.max(dim=-1).values.max(dim=-1).values.flatten()\n",
    "        # plot histogram of errors\n",
    "        display(px.histogram(error.flatten()))\n",
    "        biggest_mistakes_flat = error.topk(nb_examples).indices\n",
    "        incorrect_indices = t.stack([biggest_mistakes_flat // 59, biggest_mistakes_flat % 59],\n",
    "                                    dim=-1)\n",
    "    else:\n",
    "\n",
    "        predictions = probabilities > (1 / (threshold * nb_valid_moves))\n",
    "        correct = predictions == valid_moves\n",
    "        correct_boards = (predictions == valid_moves).all(-1).all(-1)\n",
    "\n",
    "        # Find the indices of the incorrect moves\n",
    "        incorrect_indices = t.nonzero(~correct_boards, as_tuple=False)\n",
    "        # Sample from the incorrect indices\n",
    "        incorrect_indices = incorrect_indices[t.randperm(len(incorrect_indices))]\n",
    "        incorrect_indices = incorrect_indices[:nb_examples]\n",
    "\n",
    "    # Plot the incorrect moves\n",
    "    for game, move in incorrect_indices:\n",
    "        explain_game(tokens[game],\n",
    "                     model,\n",
    "                     move,\n",
    "                     extra_boards={\n",
    "                         \"Model's mistakes\": ~correct[game, move],\n",
    "                     })\n",
    "        # plot_board(TOKENS_TO_BOARD[tokens[game]])\n",
    "\n",
    "\n",
    "find_fail_datapoints(\n",
    "    model,\n",
    "    val_tokens[:20],\n",
    "    threshold=10,\n",
    "    nb_examples=1,\n",
    "    biggest_mistakes=False,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_heads = False\n",
    "\n",
    "n_games = 50\n",
    "tokens = full_games_tokens[-n_games:].to(device)\n",
    "board_index = full_games_board_index[-n_games:].to(device)\n",
    "get_metrics = lambda model: get_loss(model, tokens, board_index, 5, -5).to_tensor()\n",
    "zero_ablation_metrics = zero_ablation(model, get_metrics, individual_heads).cpu()\n",
    "base_metrics = get_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "x_labels = [f\"Head {i}\" for i in range(model.cfg.n_heads)] + [\"All Heads\", \"MLP\"]\n",
    "y_labels = [f\"Layer {i}\" for i in range(model.cfg.n_layers)]\n",
    "if not individual_heads:\n",
    "    x_labels = x_labels[-2:]\n",
    "\n",
    "imshow(\n",
    "    zero_ablation_metrics[:3] - base_metrics[:3, None, None],\n",
    "    title=\"Metric increase after zeroing each component\",\n",
    "    x=x_labels,\n",
    "    y=y_labels,\n",
    "    facet_col=0,\n",
    "    facet_labels=[\"Loss\", \"Cell accuracy\", \"Board accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abblate all attention after the layer `n`\n",
    "\n",
    "def filter(name: str, start_layer: int = 0):\n",
    "    if not name.startswith(\"blocks.\"):\n",
    "        # 'hook_embed' or 'hook_pos_embed' or 'ln_final.hook_scale' or 'ln_final.hook_normalized'\n",
    "        return False\n",
    "\n",
    "    layer = int(name.split(\".\")[1])\n",
    "\n",
    "    return layer >= start_layer and \"attn_out\" in name\n",
    "\n",
    "metrics_per_layer = []\n",
    "for start_layer in range(model.cfg.n_layers):\n",
    "    with model.hooks(fwd_hooks=[(partial(filter, start_layer=start_layer),\n",
    "                                    zero_ablation_hook)]):\n",
    "        metrics_per_layer.append(get_metrics(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot\n",
    "lines = t.stack(metrics_per_layer, dim=1).cpu()\n",
    "line(\n",
    "    lines[:3],\n",
    "    x=[f\"≥ {i}\" for i in range(model.cfg.n_layers)],\n",
    "    facet_col=0,\n",
    "    #  facet_col_wrap=3,\n",
    "    facet_labels=[\n",
    "        \"Loss\",\n",
    "        \"Cell accuracy\",\n",
    "        \"Board accuracy\",\n",
    "    ],  # 'False Positive', 'False Negative', 'True Positive', 'True Negative'],\n",
    "    title=\"Metrics after zeroing all attention heads above a layer\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neel_probe = get_neels_probe(False, device)\n",
    "\n",
    "blank_probe, my_probe, their_probe = neel_probe.unbind(dim=-1)\n",
    "blank_direction = blank_probe - (their_probe + my_probe) / 2\n",
    "my_direction = my_probe - their_probe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aggregate_metric(\n",
    "    val_tokens,\n",
    "    model,\n",
    "    neel_probe,\n",
    "    # per_option=True,\n",
    "    # per_move=\"cell_accuracy\",\n",
    "    per_move=\"board_accuracy\",\n",
    "    name=\"Neel's probe\",\n",
    "    # prediction=\"softmax\",\n",
    "    # prediction='logprob',\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for probe, name in zip([blank_probe, their_probe, my_probe], [\"blank\", \"their\", \"my\"]):\n",
    "    probe = einops.rearrange(probe, \"d_model rows cols -> (rows cols) d_model\")\n",
    "    plot_similarities(probe,\n",
    "                      title=f\"Similarity between {name} vectors\",\n",
    "                      x=full_board_labels,\n",
    "                      y=full_board_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Similarity between mine and theirs (for each square)\n",
    "plot_similarities_2(my_probe, their_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = [get_probe(i, device=device) for i in range(3)]\n",
    "\n",
    "for probe, name in zip(probes, [\"new probe\", \"orthogonal probe\", \"orthogonal probe 2\"]):\n",
    "    plot_probe_accuracy(\n",
    "        model,\n",
    "        probe.to(device),\n",
    "        full_games_tokens[-100:],\n",
    "        full_games_board_index[-100:],\n",
    "        per_option=True,\n",
    "        name=name,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities between the blank probe and the token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embs = model.W_E[1:]\n",
    "token_embs_64 = t.zeros((64, token_embs.shape[1]), device=token_embs.device)\n",
    "token_embs_64[TOKENS_TO_BOARD] = token_embs\n",
    "print(token_embs.shape)\n",
    "token_embs_64 = einops.rearrange(token_embs_64, \"(rows cols) d_model -> d_model rows cols\", rows=8)\n",
    "\n",
    "plot_similarities_2(\n",
    "    neel_probe[..., 0],\n",
    "    token_embs_64,\n",
    "    name=\"Blank probe and token embeddings\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and show probe vector norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_norm = neel_probe.norm(dim=0)\n",
    "px.histogram(probe_norm.cpu().flatten(), title=\"Probe vector norms\", labels={\"value\": \"norm\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import umap\n",
    "import umap.plot\n",
    "import pandas as pd\n",
    "\n",
    "vectors = einops.rearrange(linear_probe,\n",
    "                            \"d_model rows cols options -> (options rows cols) d_model\")\n",
    "\n",
    "mapper = umap.UMAP(metric=\"cosine\").fit(vectors.cpu().numpy())\n",
    "\n",
    "labels = [probe_name for probe_name in [\"blank\", \"their\", \"my\"] for _ in full_board_labels]\n",
    "hover_data = pd.DataFrame({\n",
    "    \"square\": full_board_labels * 3,\n",
    "    \"probe\": labels,\n",
    "})\n",
    "\n",
    "umap.plot.show_interactive(\n",
    "    umap.plot.interactive(mapper, labels=labels, hover_data=hover_data, theme=\"inferno\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_probe = get_probe(device)\n",
    "\n",
    "# %% Run PCA on the vectors of the probe\n",
    "vectors = einops.rearrange(linear_probe, \"d_model rows cols options -> (options rows cols) d_model\")\n",
    "plot_PCA(vectors, \"the probe vectors\")\n",
    "# %% The same be per option\n",
    "for i in range(3):\n",
    "    plot_PCA(\n",
    "        linear_probe[..., i],\n",
    "        f\"the probe vectors for option {i}\",\n",
    "        flip_dim_order=True,\n",
    "        absolute=True,\n",
    "    )\n",
    "\n",
    "# %% Normalise the probe then run PCA\n",
    "normalised_probe = linear_probe / linear_probe.norm(dim=-1, keepdim=True)\n",
    "plot_PCA(normalised_probe, \"the normalised probe vectors\", flip_dim_order=True)\n",
    "\n",
    "# %% Same PCA but with the unembeddings\n",
    "plot_PCA(model.W_U, \"the unembeddings\")\n",
    "\n",
    "# %%\n",
    "plot_PCA(model.W_pos, \"the embeddings\")\n",
    "# %%\n",
    "all_vectors = [\n",
    "    model.W_U.T,\n",
    "    model.W_E,\n",
    "    model.W_pos,\n",
    "    vectors,\n",
    "]\n",
    "all_vectors = [(v - v.mean(dim=0)) / v.std(dim=0) for v in all_vectors]\n",
    "\n",
    "plot_PCA(t.cat(all_vectors, dim=0), \"the embeddings and unembeddings\")\n",
    "# %%\n",
    "plot_PCA(t.cat([my_direction, blank_direction], dim=1).flatten(1).T, \"the direction vectors\")\n",
    "# %%\n",
    "plot_PCA(my_direction.flatten(1).T, \"the direction vectors\")\n",
    "# %%\n",
    "plot_PCA(blank_direction.flatten(1).T, \"the direction vectors\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from probes import ProbeTrainingArgs, LitLinearProbe, PROBE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_NEW_TRAINING_DATA = False\n",
    "if MAKE_NEW_TRAINING_DATA:\n",
    "    games_tokens, games_valid_moves = make_training_data()\n",
    "else:\n",
    "    games_tokens, games_valid_moves = get_training_data()\n",
    "\n",
    "games_board_index = tokens_to_board(games_tokens)\n",
    "games_states = move_sequence_to_state(games_board_index, mode=\"mine-their\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens, _ = generate_training_data(1_000, seed=69)\n",
    "valid_states = move_sequence_to_state(tokens_to_board(valid_tokens), mode=\"mine-their\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute stats on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not STATS_PATH.exists():\n",
    "    stats = compute_stats(games_states, games_valid_moves)\n",
    "else:\n",
    "    stats = t.load(STATS_PATH)\n",
    "    print(\"Stats shape:\", stats.shape)\n",
    "\n",
    "stat_names = [\"Empty\", \"My piece\", \"Their piece\", \"Valid move\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_square_as_board(\n",
    "    stats.mean(1),\n",
    "    title=\"Average frequency of each cell being ...\",\n",
    "    facet_col=0,\n",
    "    facet_labels=stat_names,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per move\n",
    "lines = stats[1:].mean((2, 3)).T\n",
    "\n",
    "df = pd.DataFrame(lines.tolist(), columns=stat_names[1:])\n",
    "df[\"Move\"] = df.index\n",
    "# Add propotion of my pieces\n",
    "df[\"Proportion of my pieces\"] = df[\"My piece\"] / (df[\"My piece\"] + df[\"Their piece\"])\n",
    "df = df.melt(id_vars=[\"Move\"], var_name=\"Cell type\", value_name=\"Frequency\")\n",
    "px.line(\n",
    "    df,\n",
    "    x=\"Move\",\n",
    "    y=\"Frequency\",\n",
    "    color=\"Cell type\",\n",
    "    title=\"Frequency of each cell being ...\",\n",
    "    labels={\n",
    "        \"value\": \"Frequency\",\n",
    "        \"index\": \"Move\"\n",
    "    },\n",
    "    # legend=stat_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot stats per cell and move\n",
    "if 0:\n",
    "    moves_to_show = [0, 5, 10, 20, 30, 40, 50, 55]\n",
    "    x = einops.rearrange(stats[:, moves_to_show], \"option m r c -> (m option) r c\")\n",
    "    labels = [f\"{name} (move {move})\" for move in moves_to_show for name in stat_names]\n",
    "\n",
    "    plot_square_as_board(\n",
    "        x,\n",
    "        facet_col=0,\n",
    "        facet_col_wrap=4,\n",
    "        facet_labels=labels,\n",
    "        title=\"Average frequency of each cell being ...\",\n",
    "        height=3000,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_probe(orthogonal=(), **kwargs):\n",
    "    args = ProbeTrainingArgs(\n",
    "        train_tokens=games_tokens,\n",
    "        valid_tokens=valid_tokens,\n",
    "        **kwargs,\n",
    "    )\n",
    "    if not 'probe_name' in kwargs:\n",
    "        args.probe_name = f'probe-{len(orthogonal)}'\n",
    "        if args.black_and_white:\n",
    "            args.probe_name += '-bw'\n",
    "        if args.correct_for_dataset_bias:\n",
    "            args.probe_name += '-unbiased'\n",
    "\n",
    "    lit_ortho_probe = LitLinearProbe(model, args, *orthogonal)\n",
    "\n",
    "    wandb.finish()\n",
    "    logger = WandbLogger(save_dir=os.getcwd() + \"/logs\", project='orthogonal-probes')\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=args.max_epochs,\n",
    "        logger=logger,\n",
    "        log_every_n_steps=5,\n",
    "        val_check_interval=100,\n",
    "        check_val_every_n_epoch=None,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=lit_ortho_probe)\n",
    "    probe = lit_ortho_probe.linear_probe\n",
    "    \n",
    "    plot_aggregate_metric(\n",
    "        valid_tokens,\n",
    "        model,\n",
    "        probe,\n",
    "        # per_option=True,\n",
    "        per_move=\"board_accuracy\",\n",
    "    )\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    path = PROBE_DIR / f\"{args.probe_name}.pt\"\n",
    "    if not path.exists():\n",
    "        t.save(lit_ortho_probe.linear_probe, path)\n",
    "        print(f\"Saved probe to {path.resolve()}\")\n",
    "    else:\n",
    "        print(f\"Warning: {path.resolve()} already exists. Not saving the probe.\")\n",
    "\n",
    "    return probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = train_probe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing residual stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_residual_stream(\n",
    "    world: Union[Int[Tensor, \"row=8 cols=8\"], str],\n",
    "    probe: Float[Tensor, \"d_model rows cols options=3\"],\n",
    ") -> Float[Tensor, \"d_model\"]:\n",
    "    \"\"\"\n",
    "    Create the embedding of a board state according to the probe\n",
    "\n",
    "    Args:\n",
    "        world: the board state, with 0 for blank, +1 for mine, -1 for theirs\n",
    "        probe: directions in the residual stream that correspond to each square.\n",
    "            The last dimension is the options, with 0 for blank, 1 for mine, 2 for theirs\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(world, str):\n",
    "        world = board_to_tensor(world)\n",
    "\n",
    "    d_model = probe.shape[0]\n",
    "    blank_direction = probe[..., 0] - (probe[..., 1] + probe[..., 2]) / 2\n",
    "    my_direction = probe[..., 1] - probe[..., 2]\n",
    "\n",
    "    world = world.to(probe.device)\n",
    "    embedding = t.zeros(d_model, device=probe.device)\n",
    "    for row in range(world.shape[0]):\n",
    "        for col in range(world.shape[1]):\n",
    "            if world[row, col] == 0:\n",
    "                embedding += blank_direction[:, row, col]\n",
    "            else:\n",
    "                embedding += my_direction[:, row, col] * world[row, col]\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# %% Try to run the model on a virtual residual stream\n",
    "\n",
    "\n",
    "def hook(activation: Float[Tensor, \"game move d_model\"], hook: HookPoint):\n",
    "    activation[:, -1] = resid\n",
    "\n",
    "\n",
    "layer = 4\n",
    "act_name = utils.get_act_name(\"resid_pre\", layer)\n",
    "osef_input = focus_games_tokens[:1, :20]  # 1 game, 20 moves\n",
    "logits = model.run_with_hooks(osef_input, fwd_hooks=[(act_name, hook)])\n",
    "\n",
    "# Plot what the model predicts\n",
    "logits = logits_to_board(logits[0, -1], \"log_prob\")\n",
    "plot_square_as_board(logits, title=\"Model predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = \"\"\"\n",
    "........\n",
    "........\n",
    "........\n",
    "...xo...\n",
    "...ox...\n",
    "........\n",
    "........\n",
    "........\n",
    "\"\"\"\n",
    "\n",
    "board_2 = \"\"\"\n",
    "........\n",
    "........\n",
    "........\n",
    "..xxxx..\n",
    ".xooooo.\n",
    ".o..ox..\n",
    ".x.oxo..\n",
    "........\n",
    "\"\"\"\n",
    "board_3 = \"\"\"\n",
    "........\n",
    "........\n",
    "........\n",
    "...xo...\n",
    "...oo...\n",
    "....o...\n",
    "........\n",
    "........\n",
    "\"\"\"\n",
    "\n",
    "board_tensor = board_to_tensor(board_3)\n",
    "resid = make_residual_stream(board_tensor, linear_probe)\n",
    "# plot_square_as_board(board_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@t.inference_mode()\n",
    "def modify_resid_given_probe(\n",
    "        model: HookedTransformer,\n",
    "        moves_orig: Int[Tensor, \"move\"],\n",
    "        moves_new: Int[Tensor, \"move\"],\n",
    "        *probes: Float[Tensor, \"d_model rows cols options=3\"],\n",
    "        layer: int = 6,\n",
    "        cells: Tuple[str, ...] = (),\n",
    "):\n",
    "    act_name = utils.get_act_name(\"resid_pre\", layer)\n",
    "    new_logits, new_cache = model.run_with_cache(\n",
    "        moves_new,\n",
    "        names_filter=lambda name: name == act_name,\n",
    "    )\n",
    "\n",
    "    def hook(orig_activation: Float[Tensor, \"game move d_model\"], hook: HookPoint):\n",
    "        # Step 0. Find a basis of the subspace of the probe\n",
    "        # collect the probe vectors\n",
    "        all_probes = t.stack(probes, dim=-1).to(orig_activation.device)\n",
    "        if cells:\n",
    "            rows_cols = t.tensor([board_label_to_row_col(cell) for cell in cells])\n",
    "            all_probes = all_probes[:, rows_cols[:, 0], rows_cols[:, 1]]\n",
    "\n",
    "        probe_vectors = einops.rearrange(all_probes, \"d_model ... -> (...) d_model\")\n",
    "\n",
    "        orig_activation[:, -1] = swap_subspace(\n",
    "            orig_activation[:, -1],\n",
    "            new_cache[act_name][:, -1],\n",
    "            probe_vectors,\n",
    "        )\n",
    "\n",
    "    patched_logits = model.run_with_hooks(\n",
    "        moves_orig,\n",
    "        fwd_hooks=[(act_name, hook)],\n",
    "    )\n",
    "\n",
    "    # display the logits\n",
    "    orig_valid_moves = move_sequence_to_state(tokens_to_board(moves_orig), mode=\"valid\")\n",
    "    if cells:\n",
    "        rows_cols = [board_label_to_row_col(cell) for cell in cells]\n",
    "        index = tuple(zip(*rows_cols))\n",
    "\n",
    "        # Compute the state of orig and new board\n",
    "        new_board_state = move_sequence_to_state(tokens_to_board(moves_new), mode=\"normal\")[0, -1]\n",
    "        orig_board_state = move_sequence_to_state(tokens_to_board(moves_orig), mode=\"normal\")[0, -1]\n",
    "        # Put the cells of the new board in the orig board\n",
    "        orig_board_state[index] = new_board_state[index]\n",
    "\n",
    "        valid_cells = valid_moves_from_board(orig_board_state, moves_orig.shape[1])\n",
    "        new_valid_moves = one_hot(valid_cells).reshape(1, 1, 8, 8)\n",
    "\n",
    "    else:\n",
    "        new_valid_moves = move_sequence_to_state(tokens_to_board(moves_new), mode=\"valid\")\n",
    "\n",
    "    orig_logits = logits_to_board(model(moves_orig)[0, -1], \"log_prob\")\n",
    "    patched_logits = logits_to_board(patched_logits[0, -1], \"log_prob\")\n",
    "    new_logits = logits_to_board(new_logits[0, -1], \"log_prob\")\n",
    "\n",
    "    scale = new_logits.abs().max().cpu()\n",
    "\n",
    "    to_stack = [\n",
    "        orig_valid_moves[0, -1] * scale,\n",
    "        orig_logits,\n",
    "        patched_logits,\n",
    "        new_logits,\n",
    "        new_valid_moves[0, -1] * scale,\n",
    "        patched_logits - orig_logits,\n",
    "    ]\n",
    "\n",
    "    all_logits = t.stack([t.cpu() for t in to_stack], dim=-1)\n",
    "    plot_square_as_board(\n",
    "        all_logits,\n",
    "        title=\"Model predictions\",\n",
    "        facet_col=-1,\n",
    "        facet_col_wrap=3,\n",
    "        facet_labels=[\n",
    "            \"New expected\",\n",
    "            \"new logits\",\n",
    "            \"logit diff (patch - orig)\",\n",
    "            \"original expected\",\n",
    "            \"original logits\",\n",
    "            \"patched logits\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # plot_square_as_board(logits_to_board(new_logits[0, -1], 'log_prob'),\n",
    "    #                      title=\"Model predictions (new)\")\n",
    "    # plot_square_as_board(logits_to_board(patched_logits[0, -1], 'log_prob'),\n",
    "    #                      title=\"Model predictions (patched)\")\n",
    "\n",
    "    # with model.hooks(fwd_hooks=[(act_name, hook)]):\n",
    "    #     plot_board_log_probs(\n",
    "    #         tokens_to_board(moves_new[0]),\n",
    "    #         patched_logits[0],\n",
    "    #     )\n",
    "\n",
    "\n",
    "orig_index = 2\n",
    "new_index = 3\n",
    "move_index = 20\n",
    "layer = 4\n",
    "orig_games = focus_games_tokens[orig_index:orig_index + 1, :move_index]\n",
    "new_games = focus_games_tokens[new_index:new_index + 1, :move_index]\n",
    "\n",
    "modify_resid_given_probe(model, orig_games, new_games, *probes, layer=layer, cells=[\"D2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_board(focus_games_board_index[orig_index, :move_index], title=\"Original game\")\n",
    "plot_single_board(focus_games_board_index[new_index, :move_index], title=\"New game\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello-wfvDuSXh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
