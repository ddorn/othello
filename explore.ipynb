{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of OthelloGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(1 + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T15:29:43.387369457Z",
     "start_time": "2023-06-17T15:29:43.275299501Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T15:29:44.572874267Z",
     "start_time": "2023-06-17T15:29:44.530910330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "# os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "from functools import partial\n",
    "from typing import Tuple, Union, Dict, Literal\n",
    "\n",
    "from rich import print as rprint\n",
    "from circuitsvis.attention import attention_patterns\n",
    "import einops\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch as t\n",
    "import transformer_lens.utils as utils\n",
    "from dataclasses import dataclass, asdict\n",
    "import wandb\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "from plotly_utils import imshow\n",
    "\n",
    "import circuitsvis\n",
    "\n",
    "import utils as u\n",
    "import circuit\n",
    "from utils import *\n",
    "from plotting import *\n",
    "from probes import get_probe, get_neels_probe, ProbeTrainingArgs, LitLinearProbe\n",
    "\n",
    "from othello_world.mechanistic_interpretability.mech_interp_othello_utils import (\n",
    "    plot_single_board, )\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Things that you probably always want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T15:29:47.639925340Z",
     "start_time": "2023-06-17T15:29:47.266249147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "t.set_grad_enabled(False)\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg, model = get_othello_gpt(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tokens, val_valid = generate_training_data(100, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Loading sample data\n",
    "full_games_tokens, full_games_board_index = load_sample_games()\n",
    "num_games = 50\n",
    "focus_games_tokens = full_games_tokens[:num_games]\n",
    "focus_games_board_index = full_games_board_index[:num_games]\n",
    "assert (TOKENS_TO_BOARD[focus_games_tokens] == focus_games_board_index).all()\n",
    "\n",
    "focus_states = move_sequence_to_state(focus_games_board_index)\n",
    "focus_valid_moves = move_sequence_to_state(focus_games_board_index, mode=\"valid\")\n",
    "\n",
    "print(\"focus states:\", focus_states.shape)\n",
    "print(\"focus_valid_moves\", focus_valid_moves.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Othello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = move_sequence_to_state(tokens_to_board(val_tokens[:1]), mode=\"black-white\")\n",
    "print(states.shape)\n",
    "(circuit.Kuit(model, states[0], [\"move\", \"row\", \"col\"])\n",
    "    .new_dim('facet')\n",
    "    .by('move', 'facet')\n",
    "    .plot()\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuit = circuit.Kuit(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kuit.pos_embedding(True)\n",
    "     .plot(title=\"Normalised positional embedding matrix\")\n",
    ")\n",
    "(kuit.embedding(True)\n",
    "     .plot(title=\"Normalised token embedding matrix\")\n",
    "     .flatten()\n",
    "     .histogram(title=\"Histogram of normalised token embeddings values\")\n",
    ")\n",
    "(kuit.embedding()\n",
    "     .norm('dmodel')\n",
    "     [1:]  # skip the first one, which is big\n",
    "     .histogram(title=\"Histogram of token embeddings norms\", nbins=50)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token embeddings seem kinda 1-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of > 0.5 values along dmodel\n",
    "threshold = 0.2\n",
    "(kuit.embedding(True)\n",
    "     (lambda x: x.abs() > threshold)\n",
    "     .sum('vocab')\n",
    "     .line(title=f\"Number of tokens with embedding value > {threshold}\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kuit.pos_embedding(True)\n",
    "     .pos_embedding(True)\n",
    "     .plot(title=\"Cosine similarity between positional embeddings\")\n",
    "     ['pos_1', ::2]\n",
    "     ['pos_2', ::2]\n",
    "     .plot(title=\"Cosine similarity between even positional embeddings\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kuit.embedding(True)\n",
    "     .embedding(True)\n",
    "     .remove_diag()\n",
    "     .tokens_to_board('vocab_2', 0)\n",
    "     .new_dim('facet')\n",
    "     .by('vocab_1', 'facet')\n",
    "     .plot(title=\"Cosine similarity between token embeddings\",\n",
    "           height=600)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QK circuit of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (kuit\n",
    "#     .embedding()\n",
    "#     .new_dim('pos')\n",
    "#     .add(kuit.pos_embedding())\n",
    "#     .qk(0, key=kuit.embedding(), softmax=True)\n",
    "#     .by(\"pos\", \"head\")\n",
    "# ).plot()\n",
    "\n",
    "(kuit\n",
    "    .pos_embedding()\n",
    "    .normalise('dmodel')\n",
    "    .qk(0, key=kuit\n",
    "        .pos_embedding()\n",
    "        .normalise('dmodel')\n",
    "    )\n",
    "    .softmax()\n",
    "        (lambda x: x * t.arange(1, 60, device=device)[:, None].float())\n",
    "    .by('head')\n",
    "    .plot(title=\"Attention score from positional embeddings matching\")\n",
    ")\n",
    "    \n",
    "\n",
    "(kuit\n",
    "    .embedding()\n",
    "    .new_dim('pos')\n",
    "    .add(kuit.pos_embedding())\n",
    "    .norm(dim='dmodel')\n",
    "    ['vocab', 1:]\n",
    "    ['pos', 2:]\n",
    "    .plot(title=\"Distribution of the norm of the positional embeddings + token embeddings\",\n",
    "          height=800)\n",
    "    .flatten('vocab', 'pos')\n",
    "    .histogram(title=\"Distribution of the norm of the positional embeddings + token embeddings\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# (C\n",
    "#     .embedding()\n",
    "#     .new_dim('pos')\n",
    "#     .add(C.pos_embedding())\n",
    "#     .qk(0, key=C\n",
    "#         .embedding())\n",
    "#     .softmax()\n",
    "# ).plot('head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "pos = kuit.pos_embedding()\n",
    "pos.name = \"pos\"\n",
    "emb = kuit.embed(val_tokens[0, :59], positional=False)\n",
    "emb.name = \"emb\"\n",
    "\n",
    "move_labels = [to_board_label(tokens_to_board(t)) for t in val_tokens[0, :59]]\n",
    "\n",
    "for key, query in product([pos, emb], [pos, emb]):\n",
    "    (key.normalise('dmodel')\n",
    "        .qk(0,\n",
    "            key=key.normalise('dmodel'),\n",
    "        )\n",
    "        .softmax()\n",
    "        (lambda x: x * t.arange(1, 60, device=device)[:, None].float())\n",
    "        .by('head')\n",
    "        .plot(facet_col_wrap=4, \n",
    "              title=f\"Attention score from {key.name} matching {query.name}\",\n",
    "              x=move_labels,\n",
    "              y=move_labels,\n",
    "        )\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 15\n",
    "\n",
    "pos_emb = model.W_pos[1:]\n",
    "pos_emb_normalised = pos_emb / pos_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "pca = plot_PCA(pos_emb, name=\"Positional embeddings\")\n",
    "# Show which positions are aligned with the PCA axes (first 4)\n",
    "pca_directions = pca.components_[:num_components]\n",
    "pca_directions = t.tensor(pca_directions, device=device)\n",
    "\n",
    "\n",
    "# Show the dot product between the PCA directions and the positional embeddings\n",
    "imshow(pca_directions @ pos_emb_normalised.T,\n",
    "        xaxis_title=\"Position\",\n",
    "        yaxis_title=\"PCA direction index\",\n",
    "       title=\"Dot product between PCA directions and positional embeddings\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other QK circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 7\n",
    "(kuit\n",
    "    .embedding(True)\n",
    "    .qk(layer, key=kuit.embedding(True))\n",
    "    .tokens_to_board('vocab_k', 0)\n",
    "    .print()\n",
    "    .by('vocab_q', 'head')\n",
    "    .plot(title=\"Attention score from each embedding as query, to each embedding as key\",\n",
    "          height=900, facet_col_wrap=4)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emb - OV - Unemb circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(circuit.Kuit(model)\n",
    "    .embedding()\n",
    "    .normalise('dmodel')\n",
    "    .print()\n",
    "    .ov(0)\n",
    "    .print()\n",
    "    .unembed()\n",
    "    # .unembed_bias()\n",
    "    .by('head')\n",
    "    .plot(facet_col_wrap=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Circuit(model)\n",
    "    .unembed_bias()\n",
    "    .tokens_to_board(fill=0)\n",
    "    .plot(title=\"Unembedding bias\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and failures of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = ModelMetricPlotter(val_tokens, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.plot_loss_per_move(True)\n",
    "model_metrics.plot_loss_per_move()\n",
    "model_metrics.plot_whole_board_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_game(\n",
    "    tokens: Int[Tensor, 'move'],\n",
    "    model: HookedTransformer,\n",
    "    move: int = None,\n",
    "    # Extra args\n",
    "    extra_boards: Optional[Dict[str, Tensor]] = None,\n",
    ") -> None:\n",
    "    if isinstance(tokens, list):\n",
    "        tokens = t.tensor(tokens, dtype=t.long)\n",
    "    if move is None:\n",
    "        move = tokens.shape[0] - 1\n",
    "    move = move % tokens.shape[0]\n",
    "    if extra_boards is None:\n",
    "        extra_boards = {}\n",
    "        \n",
    "    tokens = tokens[None, :move+1].to(model.cfg.device)\n",
    "    board_indices = tokens_to_board(tokens)\n",
    "\n",
    "    logits = model(tokens)\n",
    "\n",
    "    scale = logits.abs().max().item() * 0.5\n",
    "    predictions = logits_to_board(logits, 'log_prob')\n",
    "    state = move_sequence_to_state(board_indices, 'mine-their') * scale\n",
    "    valid = move_sequence_to_state(board_indices, mode=\"valid\") * scale\n",
    "\n",
    "    # Scale extra boards if they are boolean\n",
    "    for k, v in extra_boards.items():\n",
    "        if v.dtype == t.bool:\n",
    "            extra_boards[k] = v * scale\n",
    "\n",
    "    # Plotting\n",
    "    boards = t.stack([\n",
    "        state[0, -1],\n",
    "        valid[0, -1],\n",
    "        predictions[0, -1],\n",
    "        *extra_boards.values(),\n",
    "    ], dim=0)\n",
    "    plot_square_as_board(\n",
    "        boards,\n",
    "        facet_col=0,\n",
    "        facet_col_wrap=3 if len(boards) != 4 else 2,\n",
    "        facet_labels=[\"State before\", \"Valid moves\", \"Model logits\", *extra_boards.keys()],\n",
    "        title=f\"Game after {to_board_label(board_indices[0, -1].item())} - blue to play - move {move}\",\n",
    "    )\n",
    "\n",
    "\n",
    "explain_game([20, 19], model)\n",
    "explain_game(val_tokens[3], model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@t.inference_mode()\n",
    "def find_fail_datapoints(\n",
    "    model: HookedTransformer,\n",
    "    tokens: Int[Tensor, 'game move'],\n",
    "    threshold: float = 3,\n",
    "    nb_examples: int = 10,\n",
    "    biggest_mistakes: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Find datapoints where the model fails to predict the valid moves.\n",
    "\n",
    "    Plots the board for each datapoint where the model fails to predict the valid moves.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the probabilities for each cell\n",
    "    tokens = tokens[:, :59].to(model.cfg.device)\n",
    "    logits = model(tokens[:, :59])\n",
    "    probabilities = logits_to_board(logits, 'prob')  # [game, move, row, col]\n",
    "\n",
    "    # Compute the number of valid moves\n",
    "    valid_moves = move_sequence_to_state(tokens_to_board(tokens), mode=\"valid\")[:, :59]\n",
    "    nb_valid_moves = valid_moves.sum(dim=(-1, -2), keepdim=True)  # [game, move, 1, 1]\n",
    "\n",
    "    # Find which moves are considered correct\n",
    "    if biggest_mistakes:\n",
    "        error = t.zeros_like(probabilities)\n",
    "        error[valid_moves] = 1 - (probabilities * nb_valid_moves)[valid_moves]\n",
    "        error[~valid_moves] = (probabilities * nb_valid_moves)[~valid_moves]\n",
    "        error = error.max(dim=-1).values.max(dim=-1).values.flatten()\n",
    "        # plot histogram of errors\n",
    "        display(px.histogram(error.flatten()))\n",
    "        biggest_mistakes_flat = error.topk(nb_examples).indices\n",
    "        incorrect_indices = t.stack([biggest_mistakes_flat // 59, biggest_mistakes_flat % 59],\n",
    "                                    dim=-1)\n",
    "    else:\n",
    "\n",
    "        predictions = probabilities > (1 / (threshold * nb_valid_moves))\n",
    "        correct = predictions == valid_moves\n",
    "        correct_boards = (predictions == valid_moves).all(-1).all(-1)\n",
    "\n",
    "        # Find the indices of the incorrect moves\n",
    "        incorrect_indices = t.nonzero(~correct_boards, as_tuple=False)\n",
    "        # Sample from the incorrect indices\n",
    "        incorrect_indices = incorrect_indices[t.randperm(len(incorrect_indices))]\n",
    "        incorrect_indices = incorrect_indices[:nb_examples]\n",
    "\n",
    "    # Plot the incorrect moves\n",
    "    for game, move in incorrect_indices:\n",
    "        explain_game(tokens[game],\n",
    "                     model,\n",
    "                     move,\n",
    "                     extra_boards={\n",
    "                         \"Model's mistakes\": ~correct[game, move],\n",
    "                     })\n",
    "        # plot_board(TOKENS_TO_BOARD[tokens[game]])\n",
    "\n",
    "\n",
    "find_fail_datapoints(\n",
    "    model,\n",
    "    val_tokens[:40, :30],\n",
    "    threshold=2,\n",
    "    nb_examples=10,\n",
    "    biggest_mistakes=False,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_attention(model: HookedTransformer, tokens: Int[Tensor, \"game move\"],\n",
    "                           *layers: int):\n",
    "\n",
    "    move_nb = min(tokens.shape[1], 59)\n",
    "    total_attention = t.zeros(model.cfg.n_layers, model.cfg.n_heads, move_nb, move_nb, device=model.cfg.device)\n",
    "    def hook(activation: Float[Tensor, \"game head query key\"], hook: HookPoint):\n",
    "        total_attention[hook.layer()] += activation.mean(0)\n",
    "\n",
    "    model.run_with_hooks(tokens[:, :59], fwd_hooks=[\n",
    "        (lambda n: 'pattern' in n, hook)\n",
    "    ])\n",
    "\n",
    "    # Plot all the attention patterns\n",
    "    if not layers:\n",
    "        layers = list(range(model.cfg.n_layers))\n",
    "    else:\n",
    "        layers = list(layers)\n",
    "    \n",
    "    plots = einops.rearrange(total_attention[layers], \"layer head row col -> (layer head) row col\")\n",
    "    labels = [f\"Head {head} Layer {layer}\" for layer in layers for head in range(model.cfg.n_heads)]\n",
    "    tokens_labels = [f\" {i}\" for i in range(move_nb)]\n",
    "    display(circuitsvis.attention.attention_patterns(tokens_labels, plots, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_attention(model, val_tokens[:1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_head_attention(model: HookedTransformer, tokens: Int[Tensor, \"game move\"], \n",
    "                        layer: int,\n",
    "                        head: int):\n",
    "    move_nb = min(tokens.shape[1], 59)\n",
    "    attention = t.zeros(tokens.shape[0], move_nb, move_nb, device=model.cfg.device)\n",
    "    def hook(activation: Float[Tensor, \"game head query key\"], hook: HookPoint):\n",
    "        attention[...] += activation[:, head]\n",
    "\n",
    "    model.run_with_hooks(tokens[:, :59], fwd_hooks=[\n",
    "        (utils.get_act_name('pattern', layer), hook)\n",
    "    ])\n",
    "\n",
    "    # Plot the attention patterns\n",
    "    tokens_labels = [f\" {i}\" for i in range(move_nb)]\n",
    "    return circuitsvis.attention.attention_patterns(\n",
    "        tokens_labels,\n",
    "        attention,\n",
    "        # [f\"Head {head} Layer {layer} - game {i}\" for i in range(tokens.shape[0])],\n",
    "    )\n",
    "\n",
    "plot_head_attention(model, val_tokens[:12], 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "name = utils.get_act_name('pattern', layer)\n",
    "_, cache = model.run_with_cache(val_tokens[:1, :59], names_filter=lambda n: n == name)\n",
    "pattern = cache[name][0]\n",
    "\n",
    "(circuit.Kuit(model, pattern, ['head', 'pos_q', 'pos_k'])\n",
    "pattern.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_heads = False\n",
    "\n",
    "n_games = 50\n",
    "tokens = full_games_tokens[-n_games:].to(device)\n",
    "board_index = full_games_board_index[-n_games:].to(device)\n",
    "get_metrics = lambda model: get_loss(model, tokens, board_index, 5, -5).to_tensor()\n",
    "zero_ablation_metrics = zero_ablation(model, get_metrics, individual_heads).cpu()\n",
    "base_metrics = get_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "x_labels = [f\"Head {i}\" for i in range(model.cfg.n_heads)] + [\"All Heads\", \"MLP\"]\n",
    "y_labels = [f\"Layer {i}\" for i in range(model.cfg.n_layers)]\n",
    "if not individual_heads:\n",
    "    x_labels = x_labels[-2:]\n",
    "\n",
    "imshow(\n",
    "    zero_ablation_metrics[:3] - base_metrics[:3, None, None],\n",
    "    title=\"Metric increase after zeroing each component\",\n",
    "    x=x_labels,\n",
    "    y=y_labels,\n",
    "    facet_col=0,\n",
    "    facet_labels=[\"Loss\", \"Cell accuracy\", \"Board accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abblate all attention after the layer `n`\n",
    "\n",
    "def filter(name: str, start_layer: int = 0):\n",
    "    if not name.startswith(\"blocks.\"):\n",
    "        # 'hook_embed' or 'hook_pos_embed' or 'ln_final.hook_scale' or 'ln_final.hook_normalized'\n",
    "        return False\n",
    "\n",
    "    layer = int(name.split(\".\")[1])\n",
    "\n",
    "    return layer >= start_layer and \"attn_out\" in name\n",
    "\n",
    "metrics_per_layer = []\n",
    "for start_layer in range(model.cfg.n_layers):\n",
    "    with model.hooks(fwd_hooks=[(partial(filter, start_layer=start_layer),\n",
    "                                    zero_ablation_hook)]):\n",
    "        metrics_per_layer.append(get_metrics(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot\n",
    "lines = t.stack(metrics_per_layer, dim=1).cpu()\n",
    "line(\n",
    "    lines[:3],\n",
    "    x=[f\"â‰¥ {i}\" for i in range(model.cfg.n_layers)],\n",
    "    facet_col=0,\n",
    "    #  facet_col_wrap=3,\n",
    "    facet_labels=[\n",
    "        \"Loss\",\n",
    "        \"Cell accuracy\",\n",
    "        \"Board accuracy\",\n",
    "    ],  # 'False Positive', 'False Negative', 'True Positive', 'True Negative'],\n",
    "    title=\"Metrics after zeroing all attention heads above a layer\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neel_probe = get_neels_probe(False, device)\n",
    "\n",
    "blank_probe, my_probe, their_probe = neel_probe.unbind(dim=-1)\n",
    "blank_direction = blank_probe - (their_probe + my_probe) / 2\n",
    "my_direction = my_probe - their_probe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aggregate_metric(\n",
    "    val_tokens,\n",
    "    model,\n",
    "    neel_probe,\n",
    "    # per_option=True,\n",
    "    # per_move=\"cell_accuracy\",\n",
    "    # per_move=\"board_accuracy\",\n",
    "    name=\"Neel's probe\",\n",
    "    # prediction=\"softmax\",\n",
    "    # prediction='logprob',\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for probe, name in zip([blank_probe, their_probe, my_probe], [\"blank\", \"their\", \"my\"]):\n",
    "    probe = einops.rearrange(probe, \"d_model rows cols -> (rows cols) d_model\")\n",
    "    plot_similarities(probe,\n",
    "                      title=f\"Similarity between {name} vectors\",\n",
    "                      x=full_board_labels,\n",
    "                      y=full_board_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Similarity between mine and theirs (for each square)\n",
    "plot_similarities_2(my_probe, their_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = [get_probe(i, device=device) for i in range(1)]\n",
    "\n",
    "for probe, name in zip(probes, [\"new probe\", \"orthogonal probe\", \"orthogonal probe 2\"]):\n",
    "    plot_agreggate_metric(\n",
    "        model,\n",
    "        probe.to(device),\n",
    "        full_games_tokens[-100:],\n",
    "        full_games_board_index[-100:],\n",
    "        per_option=True,\n",
    "        name=name,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities between the blank probe and the token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embs = model.W_E[1:]\n",
    "token_embs_64 = t.zeros((64, token_embs.shape[1]), device=token_embs.device)\n",
    "token_embs_64[TOKENS_TO_BOARD] = token_embs\n",
    "print(token_embs.shape)\n",
    "token_embs_64 = einops.rearrange(token_embs_64, \"(rows cols) d_model -> d_model rows cols\", rows=8)\n",
    "\n",
    "plot_similarities_2(\n",
    "    neel_probe[..., 0],\n",
    "    token_embs_64,\n",
    "    name=\"Blank probe and token embeddings\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and show probe vector norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_norm = neel_probe.norm(dim=0)\n",
    "px.histogram(probe_norm.cpu().flatten(), title=\"Probe vector norms\", labels={\"value\": \"norm\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import umap\n",
    "import umap.plot\n",
    "import pandas as pd\n",
    "\n",
    "vectors = einops.rearrange(linear_probe,\n",
    "                            \"d_model rows cols options -> (options rows cols) d_model\")\n",
    "\n",
    "mapper = umap.UMAP(metric=\"cosine\").fit(vectors.cpu().numpy())\n",
    "\n",
    "labels = [probe_name for probe_name in [\"blank\", \"their\", \"my\"] for _ in full_board_labels]\n",
    "hover_data = pd.DataFrame({\n",
    "    \"square\": full_board_labels * 3,\n",
    "    \"probe\": labels,\n",
    "})\n",
    "\n",
    "umap.plot.show_interactive(\n",
    "    umap.plot.interactive(mapper, labels=labels, hover_data=hover_data, theme=\"inferno\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_probe = get_probe(device)\n",
    "\n",
    "# %% Run PCA on the vectors of the probe\n",
    "vectors = einops.rearrange(linear_probe, \"d_model rows cols options -> (options rows cols) d_model\")\n",
    "plot_PCA(vectors, \"the probe vectors\")\n",
    "# %% The same be per option\n",
    "for i in range(3):\n",
    "    plot_PCA(\n",
    "        linear_probe[..., i],\n",
    "        f\"the probe vectors for option {i}\",\n",
    "        flip_dim_order=True,\n",
    "        absolute=True,\n",
    "    )\n",
    "\n",
    "# %% Normalise the probe then run PCA\n",
    "normalised_probe = linear_probe / linear_probe.norm(dim=-1, keepdim=True)\n",
    "plot_PCA(normalised_probe, \"the normalised probe vectors\", flip_dim_order=True)\n",
    "\n",
    "# %% Same PCA but with the unembeddings\n",
    "plot_PCA(model.W_U, \"the unembeddings\")\n",
    "\n",
    "# %%\n",
    "plot_PCA(model.W_pos, \"the embeddings\")\n",
    "# %%\n",
    "all_vectors = [\n",
    "    model.W_U.T,\n",
    "    model.W_E,\n",
    "    model.W_pos,\n",
    "    vectors,\n",
    "]\n",
    "all_vectors = [(v - v.mean(dim=0)) / v.std(dim=0) for v in all_vectors]\n",
    "\n",
    "plot_PCA(t.cat(all_vectors, dim=0), \"the embeddings and unembeddings\")\n",
    "# %%\n",
    "plot_PCA(t.cat([my_direction, blank_direction], dim=1).flatten(1).T, \"the direction vectors\")\n",
    "# %%\n",
    "plot_PCA(my_direction.flatten(1).T, \"the direction vectors\")\n",
    "# %%\n",
    "plot_PCA(blank_direction.flatten(1).T, \"the direction vectors\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from probes import ProbeTrainingArgs, LitLinearProbe, PROBE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"make new training data\" and False:\n",
    "    games_tokens, games_valid_moves = make_training_data()\n",
    "else:\n",
    "    games_tokens, games_valid_moves = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_board_index = tokens_to_board(games_tokens)\n",
    "games_states = move_sequence_to_state(games_board_index, mode=\"mine-their\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokens, _ = generate_training_data(1_000, seed=69)\n",
    "valid_states = move_sequence_to_state(tokens_to_board(valid_tokens), mode=\"mine-their\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute stats on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:04:49.564874983Z",
     "start_time": "2023-06-17T17:04:49.465731527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats shape: torch.Size([4, 60, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "if not STATS_PATH.exists():\n",
    "    stats = compute_stats(games_states, games_valid_moves)\n",
    "else:\n",
    "    stats = t.load(STATS_PATH)\n",
    "    print(\"Stats shape:\", stats.shape)\n",
    "\n",
    "stat_names = [\"Empty\", \"My piece\", \"Their piece\", \"Valid move\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_square_as_board(\n",
    "    stats.mean(1),\n",
    "    title=\"Average frequency of each cell being ...\",\n",
    "    facet_col=0,\n",
    "    facet_labels=stat_names,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per move\n",
    "lines = stats[1:].mean((2, 3)).T\n",
    "\n",
    "df = pd.DataFrame(lines.tolist(), columns=stat_names[1:])\n",
    "df[\"Move\"] = df.index\n",
    "# Add propotion of my pieces\n",
    "df[\"Proportion of my pieces\"] = df[\"My piece\"] / (df[\"My piece\"] + df[\"Their piece\"])\n",
    "df = df.melt(id_vars=[\"Move\"], var_name=\"Cell type\", value_name=\"Frequency\")\n",
    "px.line(\n",
    "    df,\n",
    "    x=\"Move\",\n",
    "    y=\"Frequency\",\n",
    "    color=\"Cell type\",\n",
    "    title=\"Frequency of each cell being ...\",\n",
    "    labels={\n",
    "        \"value\": \"Frequency\",\n",
    "        \"index\": \"Move\"\n",
    "    },\n",
    "    # legend=stat_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot stats per cell and move\n",
    "if 0:\n",
    "    moves_to_show = [0, 5, 10, 20, 30, 40, 50, 55]\n",
    "    x = einops.rearrange(stats[:, moves_to_show], \"option m r c -> (m option) r c\")\n",
    "    labels = [f\"{name} (move {move})\" for move in moves_to_show for name in stat_names]\n",
    "\n",
    "    plot_square_as_board(\n",
    "        x,\n",
    "        facet_col=0,\n",
    "        facet_col_wrap=4,\n",
    "        facet_labels=labels,\n",
    "        title=\"Average frequency of each cell being ...\",\n",
    "        height=3000,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "def train_probe(args: ProbeTrainingArgs, *orthogonal):\n",
    "    if args.probe_name == ProbeTrainingArgs.probe_name:\n",
    "        args.probe_name = f'probe-{len(orthogonal)}'\n",
    "        if args.black_and_white:\n",
    "            args.probe_name += '-bw'\n",
    "        if args.correct_for_dataset_bias:\n",
    "            args.probe_name += '-unbiased'\n",
    "\n",
    "    lit_ortho_probe = LitLinearProbe(model, args, *orthogonal)\n",
    "\n",
    "    wandb.finish()\n",
    "    logger = WandbLogger(save_dir=os.getcwd() + \"/logs\", project='orthogonal-probes')\n",
    "    config = dataclasses.asdict(args)\n",
    "    del config['train_tokens']\n",
    "    del config['valid_tokens']\n",
    "    logger.log_hyperparams(config)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=args.max_epochs,\n",
    "        logger=logger,\n",
    "        log_every_n_steps=5,\n",
    "        val_check_interval=100,\n",
    "        check_val_every_n_epoch=None,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=lit_ortho_probe)\n",
    "    probe = lit_ortho_probe.linear_probe\n",
    "    \n",
    "    plot_aggregate_metric(\n",
    "        valid_tokens,\n",
    "        model,\n",
    "        probe,\n",
    "        # per_option=True,\n",
    "        per_move=\"board_accuracy\",\n",
    "    )\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    path = PROBE_DIR / f\"{args.probe_name}.pt\"\n",
    "    if not path.exists():\n",
    "        t.save(lit_ortho_probe.linear_probe, path)\n",
    "        print(f\"Saved probe to {path.resolve()}\")\n",
    "    else:\n",
    "        print(f\"Warning: {path.resolve()} already exists. Not saving the probe.\")\n",
    "\n",
    "    return probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = get_probe(0, device=device, base_name='probe-0.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe2 = train_probe(ProbeTrainingArgs(games_tokens, val_tokens, lr=0.001, batch_size=600, max_epochs=12),\n",
    "                    probe,)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training with sweeps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train with sweeps\n",
    "import yaml\n",
    "\n",
    "\n",
    "config = yaml.safe_load(Path('sweep.yml').read_text())\n",
    "rprint(config)\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=config, project='cell-probes-sweep')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run():\n",
    "    with wandb.init() as run:\n",
    "        config = run.config\n",
    "        probe_config = ProbeConfig(\n",
    "            cell=\"C4\",\n",
    "            trained_on_move=40,\n",
    "            num_valid_games=1000,\n",
    "            validate_every=20,\n",
    "            **config)\n",
    "        probe = Probe(model, probe_config)\n",
    "        probe.train(games_tokens, val_tokens)\n",
    "\n",
    "wandb.agent(sweep_id, function=run, count=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probe per move/cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T15:32:22.869281261Z",
     "start_time": "2023-06-17T15:32:07.032726716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf8e0b63d4f44107a91151d49b952962"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_tokens, _ = generate_training_data(10000, 69)\n",
    "train_tokens, _ = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;35mProbeConfig\u001B[0m\u001B[1m(\u001B[0m\n    \u001B[33mcell\u001B[0m=\u001B[32m'C4'\u001B[0m,\n    \u001B[33mtrained_on_move\u001B[0m=\u001B[1;36m12\u001B[0m,\n    \u001B[33mlayer\u001B[0m=\u001B[1;36m3\u001B[0m,\n    \u001B[33mprobe_point\u001B[0m=\u001B[32m'resid_post'\u001B[0m,\n    \u001B[33mdevice\u001B[0m=\u001B[32m'cuda'\u001B[0m,\n    \u001B[33mhas_blank\u001B[0m=\u001B[3;92mTrue\u001B[0m,\n    \u001B[33muse_wandb\u001B[0m=\u001B[3;91mFalse\u001B[0m,\n    \u001B[33mseed\u001B[0m=\u001B[1;36m42\u001B[0m,\n    \u001B[33mepochs\u001B[0m=\u001B[1;36m4\u001B[0m,\n    \u001B[33mlr\u001B[0m=\u001B[1;36m0\u001B[0m\u001B[1;36m.01\u001B[0m,\n    \u001B[33mwd\u001B[0m=\u001B[1;36m0\u001B[0m\u001B[1;36m.0\u001B[0m,\n    \u001B[33mbetas\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m0.9\u001B[0m, \u001B[1;36m0.99\u001B[0m\u001B[1m)\u001B[0m,\n    \u001B[33mval_loss_early_stop\u001B[0m=\u001B[1;36m0\u001B[0m\u001B[1;36m.0\u001B[0m,\n    \u001B[33mbatch_size\u001B[0m=\u001B[1;36m500\u001B[0m,\n    \u001B[33mnum_train_games\u001B[0m=\u001B[1;36m1000\u001B[0m,\n    \u001B[33mnum_valid_games\u001B[0m=\u001B[1;36m100\u001B[0m,\n    \u001B[33mvalidate_every\u001B[0m=\u001B[1;36m20\u001B[0m\n\u001B[1m)\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProbeConfig</span><span style=\"font-weight: bold\">(</span>\n    <span style=\"color: #808000; text-decoration-color: #808000\">cell</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'C4'</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">trained_on_move</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">layer</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">probe_point</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'resid_post'</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda'</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">has_blank</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">use_wandb</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">seed</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">epochs</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">wd</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">betas</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span><span style=\"font-weight: bold\">)</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">val_loss_early_stop</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">num_train_games</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">num_valid_games</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,\n    <span style=\"color: #808000; text-decoration-color: #808000\">validate_every</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n<span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Computing activations:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d5cbfe48bd9478e871867e383fa0868"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Computing activations:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7832a57f1d3546688b2d938263ceb071"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from probes import ProbeConfig, Probe\n",
    "\n",
    "test_config = ProbeConfig(\n",
    "    cell=\"C4\",\n",
    "    trained_on_move=12,\n",
    "    layer=3,\n",
    "    validate_every=20,\n",
    "    use_wandb=False,\n",
    "    num_train_games=1000,\n",
    "    num_valid_games=100,\n",
    ")\n",
    "rprint(test_config)\n",
    "probe = Probe(model, test_config)\n",
    "train_data = probe.dataloader_activations(train_tokens, test_config.num_train_games, shuffle=True)\n",
    "val_data = probe.dataloader_activations(val_tokens, test_config.num_valid_games, shuffle=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T15:32:23.810242620Z",
     "start_time": "2023-06-17T15:32:22.872287179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probes import ProbeConfig, Probe\n",
    "TRAIN = True\n",
    "probes = []\n",
    "for layer in range(8):\n",
    "# for layer in [3]:\n",
    "    probe_config = ProbeConfig(\n",
    "        cell=\"D3\",\n",
    "        trained_on_move=40,\n",
    "        layer=layer,\n",
    "        has_blank=False,\n",
    "        device=device,\n",
    "        epochs=12,\n",
    "        lr=0.001,\n",
    "        # wd=0.00001,\n",
    "        batch_size=1000,\n",
    "        num_train_games=100_000,\n",
    "        num_valid_games=1_000,\n",
    "        validate_every=20,\n",
    "        use_wandb=True,\n",
    "    )\n",
    "    if TRAIN:\n",
    "        probe = Probe(model, probe_config)\n",
    "\n",
    "        with wandb.init(project='position-dependent-probes',\n",
    "                        config=probe_config,\n",
    "                        mode='online' if probe_config.use_wandb else 'disabled',\n",
    "                        group=f'{probe_config.cell}-{probe_config.trained_on_move}'):\n",
    "\n",
    "            probe.train_loop(\n",
    "                # train_data,\n",
    "                # val_data,\n",
    "                probe.dataloader_activations(train_tokens, probe_config.num_train_games, shuffle=True),\n",
    "                probe.dataloader_activations(val_tokens, probe_config.num_valid_games, shuffle=False),\n",
    "                train_type='activations',\n",
    "                val_type='activations',\n",
    "            )\n",
    "        probe.save()\n",
    "    else:\n",
    "        probe = probe_config.load(model)\n",
    "    probes.append(probe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given cell and move number,\n",
    "we have a probe that tries to predict the state of the cell at every move (after every layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:18:55.953039930Z",
     "start_time": "2023-06-17T17:18:37.346714940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Converting moves to states:   0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40b0780c10764ca0841b30be1fff322e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data = probes[0].dataloader(val_tokens, 10_000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "from probes import ConstantProbe, StatsProbe\n",
    "\n",
    "heuristic = [1.0, 1.0]\n",
    "\n",
    "baseline_random = []\n",
    "baseline_stats = []\n",
    "for probe in probes:\n",
    "    config = ProbeConfig(**dataclasses.asdict(probe.config))\n",
    "    config.use_wandb = False\n",
    "    baseline_random.append(ConstantProbe(heuristic, model, config))\n",
    "    baseline_stats.append(StatsProbe(stats[:3], model, config))\n",
    "\n",
    "baseline_random = t.stack([ probe.validate(val_data) for probe in baseline_random ])\n",
    "baseline_stats = t.stack([ probe.validate(val_data) for probe in baseline_stats ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T17:19:15.399236674Z",
     "start_time": "2023-06-17T17:19:13.556254284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:19:31.674777933Z",
     "start_time": "2023-06-17T17:19:19.859852189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68498122df5840039f76c938bc617457"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the probes\n",
    "# Then make a plot with every layer on the y axis, move predicted on the x axis, \n",
    "# and the accuracy of the probe for the value\n",
    "\n",
    "# This is okay, because they are all on the same cell and move.\n",
    "\n",
    "losses = [\n",
    "    probe.validate(val_data, use_wandb=False)\n",
    "    for probe in tqdm(probes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L0resid_post-M40.pt already exists. Not saving the probe.\n",
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L1resid_post-M40.pt already exists. Not saving the probe.\n",
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L2resid_post-M40.pt already exists. Not saving the probe.\n",
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L3resid_post-M40.pt already exists. Not saving the probe.\n",
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L4resid_post-M40.pt already exists. Not saving the probe.\n",
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L5resid_post-M40.pt already exists. Not saving the probe.\n",
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L6resid_post-M40.pt already exists. Not saving the probe.\n",
      "Warning: /tmp/pycharm_project_802/probes/probe-D3-L7resid_post-M40.pt already exists. Not saving the probe.\n"
     ]
    }
   ],
   "source": [
    "for probe in probes:\n",
    "    probe.save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T17:26:44.033649710Z",
     "start_time": "2023-06-17T17:26:43.989205361Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:24:19.241886533Z",
     "start_time": "2023-06-17T17:24:19.029038453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "coloraxis": "coloraxis",
         "name": "0",
         "z": [
          [
           0.23209995031356812,
           0.41270002722740173,
           0.24900010228157043,
           0.21540012955665588,
           0.2384999394416809,
           0.18369996547698975,
           0.21150001883506775,
           0.16609996557235718,
           0.1942000687122345,
           0.16280001401901245,
           0.16190001368522644,
           0.17020004987716675,
           0.1591000258922577,
           0.1501999795436859,
           0.14710009098052979,
           0.1532999873161316,
           0.1456001102924347,
           0.13159990310668945,
           0.15089991688728333,
           0.132999986410141,
           0.12820002436637878,
           0.13110008835792542,
           0.12120005488395691,
           0.1472998857498169,
           0.1129000186920166,
           0.1424001157283783,
           0.11350008845329285,
           0.1342000663280487,
           0.11730006337165833,
           0.13620001077651978,
           0.13110002875328064,
           0.1423000693321228,
           0.13749995827674866,
           0.15530002117156982,
           0.14500001072883606,
           0.1677999496459961,
           0.1665000021457672,
           0.19120001792907715,
           0.1964000165462494,
           0.2262999713420868,
           0.254300057888031
          ],
          [
           0.22869998216629028,
           0.40320006012916565,
           0.23860004544258118,
           0.2030000388622284,
           0.2376999855041504,
           0.16600000858306885,
           0.2097000777721405,
           0.14600002765655518,
           0.18010005354881287,
           0.14009994268417358,
           0.14020004868507385,
           0.1388000249862671,
           0.13509997725486755,
           0.12320002913475037,
           0.12759995460510254,
           0.12250000238418579,
           0.12500008940696716,
           0.1012999415397644,
           0.12629994750022888,
           0.10879990458488464,
           0.11070004105567932,
           0.10530003905296326,
           0.09919998049736023,
           0.11789995431900024,
           0.09020000696182251,
           0.1228000819683075,
           0.0911000669002533,
           0.1274000108242035,
           0.09490004181861877,
           0.12680000066757202,
           0.12359997630119324,
           0.14270007610321045,
           0.14110001921653748,
           0.16019999980926514,
           0.16640004515647888,
           0.19580000638961792,
           0.2126999795436859,
           0.247700035572052,
           0.27880004048347473,
           0.3107999861240387,
           0.3242000341415405
          ],
          [
           0.21769994497299194,
           0.39139994978904724,
           0.2328999936580658,
           0.19680002331733704,
           0.23420000076293945,
           0.1622999906539917,
           0.2056000530719757,
           0.1434999704360962,
           0.17509999871253967,
           0.13180005550384521,
           0.1399000585079193,
           0.13760000467300415,
           0.1337999403476715,
           0.12529996037483215,
           0.12620002031326294,
           0.1195000410079956,
           0.12000003457069397,
           0.09719997644424438,
           0.11949995160102844,
           0.10750004649162292,
           0.10770007967948914,
           0.09950008988380432,
           0.09980002045631409,
           0.11849993467330933,
           0.0877000093460083,
           0.1283000409603119,
           0.09900006651878357,
           0.13560011982917786,
           0.11009994149208069,
           0.14120006561279297,
           0.1339000165462494,
           0.16330009698867798,
           0.1558000147342682,
           0.1898999810218811,
           0.19130000472068787,
           0.23820006847381592,
           0.25630006194114685,
           0.3007999658584595,
           0.34000006318092346,
           0.38659998774528503,
           0.39120006561279297
          ],
          [
           0.21059995889663696,
           0.38680002093315125,
           0.22830000519752502,
           0.19310006499290466,
           0.2314000129699707,
           0.1632000207901001,
           0.20550009608268738,
           0.14309996366500854,
           0.17520007491111755,
           0.13270002603530884,
           0.1391001045703888,
           0.13460004329681396,
           0.13019999861717224,
           0.12030002474784851,
           0.1239999532699585,
           0.11809998750686646,
           0.11820009350776672,
           0.09209990501403809,
           0.11869993805885315,
           0.10359999537467957,
           0.10279998183250427,
           0.0927000343799591,
           0.0949999988079071,
           0.12070000171661377,
           0.09040004014968872,
           0.13379999995231628,
           0.10160002112388611,
           0.1469000279903412,
           0.12000003457069397,
           0.15200001001358032,
           0.15740004181861877,
           0.18300002813339233,
           0.18759998679161072,
           0.2182999849319458,
           0.23550006747245789,
           0.270300030708313,
           0.30230000615119934,
           0.34790003299713135,
           0.3914000689983368,
           0.44499990344047546,
           0.4513000249862671
          ],
          [
           0.20329993963241577,
           0.3827000558376312,
           0.22729995846748352,
           0.19120004773139954,
           0.22979998588562012,
           0.16239994764328003,
           0.20520004630088806,
           0.13859999179840088,
           0.17469999194145203,
           0.12899994850158691,
           0.13440003991127014,
           0.1306999921798706,
           0.12689998745918274,
           0.11490002274513245,
           0.11810004711151123,
           0.11329996585845947,
           0.11120006442070007,
           0.08449995517730713,
           0.11539992690086365,
           0.1005999743938446,
           0.09600004553794861,
           0.09850010275840759,
           0.09049996733665466,
           0.11549997329711914,
           0.08309996128082275,
           0.13290002942085266,
           0.09830006957054138,
           0.14680001139640808,
           0.11250004172325134,
           0.15550005435943604,
           0.1581999957561493,
           0.1883000135421753,
           0.19760003685951233,
           0.23350000381469727,
           0.24980011582374573,
           0.2955999970436096,
           0.3333999812602997,
           0.3747999668121338,
           0.432000070810318,
           0.4899999797344208,
           0.4952000379562378
          ],
          [
           0.19569998979568481,
           0.3774999678134918,
           0.21790000796318054,
           0.19140002131462097,
           0.22759997844696045,
           0.1613999605178833,
           0.20430001616477966,
           0.13579994440078735,
           0.1720999777317047,
           0.13090002536773682,
           0.1325000822544098,
           0.1258000135421753,
           0.12350001931190491,
           0.1159999668598175,
           0.11810004711151123,
           0.11169999837875366,
           0.11360004544258118,
           0.08340001106262207,
           0.11529996991157532,
           0.10010001063346863,
           0.09490004181861877,
           0.0878000557422638,
           0.09430000185966492,
           0.10469990968704224,
           0.08230000734329224,
           0.1202000081539154,
           0.10200008749961853,
           0.13770005106925964,
           0.12049999833106995,
           0.156499981880188,
           0.16630002856254578,
           0.18940013647079468,
           0.20320001244544983,
           0.243399977684021,
           0.2674000561237335,
           0.3137000799179077,
           0.35419997572898865,
           0.40170007944107056,
           0.4583999812602997,
           0.5149999856948853,
           0.5204000473022461
          ],
          [
           0.1886999011039734,
           0.3774000108242035,
           0.21900001168251038,
           0.19280007481575012,
           0.22350001335144043,
           0.16169995069503784,
           0.2048000991344452,
           0.1283000111579895,
           0.1691000759601593,
           0.12359994649887085,
           0.13440003991127014,
           0.12700003385543823,
           0.12010005116462708,
           0.11689993739128113,
           0.11440002918243408,
           0.1109999418258667,
           0.10289999842643738,
           0.08560001850128174,
           0.10769996047019958,
           0.10179993510246277,
           0.0870000422000885,
           0.08510008454322815,
           0.0869000256061554,
           0.10639989376068115,
           0.07940000295639038,
           0.12250003218650818,
           0.09139999747276306,
           0.1332000195980072,
           0.1130000650882721,
           0.1527000069618225,
           0.1569000780582428,
           0.18660002946853638,
           0.19850000739097595,
           0.2400999665260315,
           0.2632000744342804,
           0.31240004301071167,
           0.3550000488758087,
           0.40740007162094116,
           0.4657000005245209,
           0.5262000560760498,
           0.5306000709533691
          ],
          [
           0.19129997491836548,
           0.382500022649765,
           0.21260002255439758,
           0.19610008597373962,
           0.22419995069503784,
           0.1613999605178833,
           0.20600005984306335,
           0.13789993524551392,
           0.1649000346660614,
           0.12099999189376831,
           0.13080009818077087,
           0.12570005655288696,
           0.11630001664161682,
           0.11939999461174011,
           0.11520004272460938,
           0.11659997701644897,
           0.09290000796318054,
           0.08859997987747192,
           0.09700003266334534,
           0.10080000758171082,
           0.08420005440711975,
           0.08900001645088196,
           0.08220002055168152,
           0.10780000686645508,
           0.07830005884170532,
           0.12170001864433289,
           0.09100005030632019,
           0.1333000361919403,
           0.11110004782676697,
           0.14459997415542603,
           0.1509999930858612,
           0.17900007963180542,
           0.1865999400615692,
           0.22710001468658447,
           0.24820002913475037,
           0.2979000210762024,
           0.33949998021125793,
           0.3952999711036682,
           0.45239993929862976,
           0.5250999927520752,
           0.5301000475883484
          ]
         ],
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0.0,
          1.0
         ],
         "scaleanchor": "y",
         "constrain": "domain",
         "title": {
          "text": "time"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.0,
          1.0
         ],
         "autorange": "reversed",
         "constrain": "domain",
         "title": {
          "text": "layer"
         }
        },
        "coloraxis": {
         "colorscale": [
          [
           0.0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1.0,
           "rgb(5,48,97)"
          ]
         ],
         "cmid": 0.0,
         "cmin": -0.5,
         "cmax": 0.5
        },
        "title": {
         "text": "Probe on move 40 trying to predict the state of D3 at given timestep<br>Accuracy improvement over baseline (dataset stats)"
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"569983e9-a911-4db9-8a0d-22b84513ea4b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"569983e9-a911-4db9-8a0d-22b84513ea4b\")) {                    Plotly.newPlot(                        \"569983e9-a911-4db9-8a0d-22b84513ea4b\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.23209995031356812,0.41270002722740173,0.24900010228157043,0.21540012955665588,0.2384999394416809,0.18369996547698975,0.21150001883506775,0.16609996557235718,0.1942000687122345,0.16280001401901245,0.16190001368522644,0.17020004987716675,0.1591000258922577,0.1501999795436859,0.14710009098052979,0.1532999873161316,0.1456001102924347,0.13159990310668945,0.15089991688728333,0.132999986410141,0.12820002436637878,0.13110008835792542,0.12120005488395691,0.1472998857498169,0.1129000186920166,0.1424001157283783,0.11350008845329285,0.1342000663280487,0.11730006337165833,0.13620001077651978,0.13110002875328064,0.1423000693321228,0.13749995827674866,0.15530002117156982,0.14500001072883606,0.1677999496459961,0.1665000021457672,0.19120001792907715,0.1964000165462494,0.2262999713420868,0.254300057888031],[0.22869998216629028,0.40320006012916565,0.23860004544258118,0.2030000388622284,0.2376999855041504,0.16600000858306885,0.2097000777721405,0.14600002765655518,0.18010005354881287,0.14009994268417358,0.14020004868507385,0.1388000249862671,0.13509997725486755,0.12320002913475037,0.12759995460510254,0.12250000238418579,0.12500008940696716,0.1012999415397644,0.12629994750022888,0.10879990458488464,0.11070004105567932,0.10530003905296326,0.09919998049736023,0.11789995431900024,0.09020000696182251,0.1228000819683075,0.0911000669002533,0.1274000108242035,0.09490004181861877,0.12680000066757202,0.12359997630119324,0.14270007610321045,0.14110001921653748,0.16019999980926514,0.16640004515647888,0.19580000638961792,0.2126999795436859,0.247700035572052,0.27880004048347473,0.3107999861240387,0.3242000341415405],[0.21769994497299194,0.39139994978904724,0.2328999936580658,0.19680002331733704,0.23420000076293945,0.1622999906539917,0.2056000530719757,0.1434999704360962,0.17509999871253967,0.13180005550384521,0.1399000585079193,0.13760000467300415,0.1337999403476715,0.12529996037483215,0.12620002031326294,0.1195000410079956,0.12000003457069397,0.09719997644424438,0.11949995160102844,0.10750004649162292,0.10770007967948914,0.09950008988380432,0.09980002045631409,0.11849993467330933,0.0877000093460083,0.1283000409603119,0.09900006651878357,0.13560011982917786,0.11009994149208069,0.14120006561279297,0.1339000165462494,0.16330009698867798,0.1558000147342682,0.1898999810218811,0.19130000472068787,0.23820006847381592,0.25630006194114685,0.3007999658584595,0.34000006318092346,0.38659998774528503,0.39120006561279297],[0.21059995889663696,0.38680002093315125,0.22830000519752502,0.19310006499290466,0.2314000129699707,0.1632000207901001,0.20550009608268738,0.14309996366500854,0.17520007491111755,0.13270002603530884,0.1391001045703888,0.13460004329681396,0.13019999861717224,0.12030002474784851,0.1239999532699585,0.11809998750686646,0.11820009350776672,0.09209990501403809,0.11869993805885315,0.10359999537467957,0.10279998183250427,0.0927000343799591,0.0949999988079071,0.12070000171661377,0.09040004014968872,0.13379999995231628,0.10160002112388611,0.1469000279903412,0.12000003457069397,0.15200001001358032,0.15740004181861877,0.18300002813339233,0.18759998679161072,0.2182999849319458,0.23550006747245789,0.270300030708313,0.30230000615119934,0.34790003299713135,0.3914000689983368,0.44499990344047546,0.4513000249862671],[0.20329993963241577,0.3827000558376312,0.22729995846748352,0.19120004773139954,0.22979998588562012,0.16239994764328003,0.20520004630088806,0.13859999179840088,0.17469999194145203,0.12899994850158691,0.13440003991127014,0.1306999921798706,0.12689998745918274,0.11490002274513245,0.11810004711151123,0.11329996585845947,0.11120006442070007,0.08449995517730713,0.11539992690086365,0.1005999743938446,0.09600004553794861,0.09850010275840759,0.09049996733665466,0.11549997329711914,0.08309996128082275,0.13290002942085266,0.09830006957054138,0.14680001139640808,0.11250004172325134,0.15550005435943604,0.1581999957561493,0.1883000135421753,0.19760003685951233,0.23350000381469727,0.24980011582374573,0.2955999970436096,0.3333999812602997,0.3747999668121338,0.432000070810318,0.4899999797344208,0.4952000379562378],[0.19569998979568481,0.3774999678134918,0.21790000796318054,0.19140002131462097,0.22759997844696045,0.1613999605178833,0.20430001616477966,0.13579994440078735,0.1720999777317047,0.13090002536773682,0.1325000822544098,0.1258000135421753,0.12350001931190491,0.1159999668598175,0.11810004711151123,0.11169999837875366,0.11360004544258118,0.08340001106262207,0.11529996991157532,0.10010001063346863,0.09490004181861877,0.0878000557422638,0.09430000185966492,0.10469990968704224,0.08230000734329224,0.1202000081539154,0.10200008749961853,0.13770005106925964,0.12049999833106995,0.156499981880188,0.16630002856254578,0.18940013647079468,0.20320001244544983,0.243399977684021,0.2674000561237335,0.3137000799179077,0.35419997572898865,0.40170007944107056,0.4583999812602997,0.5149999856948853,0.5204000473022461],[0.1886999011039734,0.3774000108242035,0.21900001168251038,0.19280007481575012,0.22350001335144043,0.16169995069503784,0.2048000991344452,0.1283000111579895,0.1691000759601593,0.12359994649887085,0.13440003991127014,0.12700003385543823,0.12010005116462708,0.11689993739128113,0.11440002918243408,0.1109999418258667,0.10289999842643738,0.08560001850128174,0.10769996047019958,0.10179993510246277,0.0870000422000885,0.08510008454322815,0.0869000256061554,0.10639989376068115,0.07940000295639038,0.12250003218650818,0.09139999747276306,0.1332000195980072,0.1130000650882721,0.1527000069618225,0.1569000780582428,0.18660002946853638,0.19850000739097595,0.2400999665260315,0.2632000744342804,0.31240004301071167,0.3550000488758087,0.40740007162094116,0.4657000005245209,0.5262000560760498,0.5306000709533691],[0.19129997491836548,0.382500022649765,0.21260002255439758,0.19610008597373962,0.22419995069503784,0.1613999605178833,0.20600005984306335,0.13789993524551392,0.1649000346660614,0.12099999189376831,0.13080009818077087,0.12570005655288696,0.11630001664161682,0.11939999461174011,0.11520004272460938,0.11659997701644897,0.09290000796318054,0.08859997987747192,0.09700003266334534,0.10080000758171082,0.08420005440711975,0.08900001645088196,0.08220002055168152,0.10780000686645508,0.07830005884170532,0.12170001864433289,0.09100005030632019,0.1333000361919403,0.11110004782676697,0.14459997415542603,0.1509999930858612,0.17900007963180542,0.1865999400615692,0.22710001468658447,0.24820002913475037,0.2979000210762024,0.33949998021125793,0.3952999711036682,0.45239993929862976,0.5250999927520752,0.5301000475883484]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"time\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-0.5,\"cmax\":0.5},\"title\":{\"text\":\"Probe on move 40 trying to predict the state of D3 at given timestep\\u003cbr\\u003eAccuracy improvement over baseline (dataset stats)\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('569983e9-a911-4db9-8a0d-22b84513ea4b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nice plot\n",
    "from circuit import MagicTensor\n",
    "\n",
    "(MagicTensor(t.stack(losses) - baseline_stats, ['layer', 'metric', 'time'])\n",
    "    .by('metric')\n",
    "    ['metric', 1]\n",
    "    .plot(title=f\"Probe on move {probes[0].config.trained_on_move} trying to predict the state of {probes[0].config.cell} at given timestep\"\n",
    "          \"<br>Accuracy improvement over baseline (dataset stats)\",\n",
    "          color_continuous_scale='RdBu',\n",
    "          color_continuous_midpoint=0.0,\n",
    "          zmax=0.5,\n",
    "          zmin=-0.5,\n",
    "          # facet_labels=[\"Loss\", \"Accuracy\"],\n",
    "          # facet_col_wrap=1,\n",
    "          )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit import MagicTensor\n",
    "(MagicTensor(t.stack([p.probe for p in probes]), ['layer', 'option', 'move', 'dmodel'])\n",
    "    .norm('dmodel')\n",
    "    ['layer', 5]\n",
    "    ['option', 0]\n",
    "    # .new_dim('facet')\n",
    "    # .flatten('move', 'dmodel')\n",
    "    # .flatten('layer', 'option')\n",
    "    .flatten()\n",
    "    .print()\n",
    "    # .histogram(nbins=100)\n",
    "    .plot()\n",
    " )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing residual stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_residual_stream(\n",
    "    world: Union[Int[Tensor, \"row=8 cols=8\"], str],\n",
    "    probe: Float[Tensor, \"d_model rows cols options=3\"],\n",
    ") -> Float[Tensor, \"d_model\"]:\n",
    "    \"\"\"\n",
    "    Create the embedding of a board state according to the probe\n",
    "\n",
    "    Args:\n",
    "        world: the board state, with 0 for blank, +1 for mine, -1 for theirs\n",
    "        probe: directions in the residual stream that correspond to each square.\n",
    "            The last dimension is the options, with 0 for blank, 1 for mine, 2 for theirs\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(world, str):\n",
    "        world = board_to_tensor(world)\n",
    "\n",
    "    d_model = probe.shape[0]\n",
    "    blank_direction = probe[..., 0] - (probe[..., 1] + probe[..., 2]) / 2\n",
    "    my_direction = probe[..., 1] - probe[..., 2]\n",
    "\n",
    "    world = world.to(probe.device)\n",
    "    embedding = t.zeros(d_model, device=probe.device)\n",
    "    for row in range(world.shape[0]):\n",
    "        for col in range(world.shape[1]):\n",
    "            if world[row, col] == 0:\n",
    "                embedding += blank_direction[:, row, col]\n",
    "            else:\n",
    "                embedding += my_direction[:, row, col] * world[row, col]\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# %% Try to run the model on a virtual residual stream\n",
    "\n",
    "\n",
    "def hook(activation: Float[Tensor, \"game move d_model\"], hook: HookPoint):\n",
    "    activation[:, -1] = resid\n",
    "\n",
    "\n",
    "layer = 4\n",
    "act_name = utils.get_act_name(\"resid_pre\", layer)\n",
    "osef_input = focus_games_tokens[:1, :20]  # 1 game, 20 moves\n",
    "logits = model.run_with_hooks(osef_input, fwd_hooks=[(act_name, hook)])\n",
    "\n",
    "# Plot what the model predicts\n",
    "logits = logits_to_board(logits[0, -1], \"log_prob\")\n",
    "plot_square_as_board(logits, title=\"Model predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = \"\"\"\n",
    "........\n",
    "........\n",
    "........\n",
    "...xo...\n",
    "...ox...\n",
    "........\n",
    "........\n",
    "........\n",
    "\"\"\"\n",
    "\n",
    "board_2 = \"\"\"\n",
    "........\n",
    "........\n",
    "........\n",
    "..xxxx..\n",
    ".xooooo.\n",
    ".o..ox..\n",
    ".x.oxo..\n",
    "........\n",
    "\"\"\"\n",
    "board_3 = \"\"\"\n",
    "........\n",
    "........\n",
    "........\n",
    "...xo...\n",
    "...oo...\n",
    "....o...\n",
    "........\n",
    "........\n",
    "\"\"\"\n",
    "\n",
    "board_tensor = board_to_tensor(board_3)\n",
    "resid = make_residual_stream(board_tensor, linear_probe)\n",
    "# plot_square_as_board(board_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@t.inference_mode()\n",
    "def modify_resid_given_probe(\n",
    "        model: HookedTransformer,\n",
    "        moves_orig: Int[Tensor, \"move\"],\n",
    "        moves_new: Int[Tensor, \"move\"],\n",
    "        *probes: Float[Tensor, \"d_model rows cols options=3\"],\n",
    "        layer: int = 6,\n",
    "        cells: Tuple[str, ...] = (),\n",
    "):\n",
    "    act_name = utils.get_act_name(\"resid_pre\", layer)\n",
    "    new_logits, new_cache = model.run_with_cache(\n",
    "        moves_new,\n",
    "        names_filter=lambda name: name == act_name,\n",
    "    )\n",
    "\n",
    "    def hook(orig_activation: Float[Tensor, \"game move d_model\"], hook: HookPoint):\n",
    "        # Step 0. Find a basis of the subspace of the probe\n",
    "        # collect the probe vectors\n",
    "        all_probes = t.stack(probes, dim=-1).to(orig_activation.device)\n",
    "        if cells:\n",
    "            rows_cols = t.tensor([board_label_to_row_col(cell) for cell in cells])\n",
    "            all_probes = all_probes[:, rows_cols[:, 0], rows_cols[:, 1]]\n",
    "\n",
    "        probe_vectors = einops.rearrange(all_probes, \"d_model ... -> (...) d_model\")\n",
    "\n",
    "        orig_activation[:, -1] = swap_subspace(\n",
    "            orig_activation[:, -1],\n",
    "            new_cache[act_name][:, -1],\n",
    "            probe_vectors,\n",
    "        )\n",
    "\n",
    "    patched_logits = model.run_with_hooks(\n",
    "        moves_orig,\n",
    "        fwd_hooks=[(act_name, hook)],\n",
    "    )\n",
    "\n",
    "    # display the logits\n",
    "    orig_valid_moves = move_sequence_to_state(tokens_to_board(moves_orig), mode=\"valid\")\n",
    "    if cells:\n",
    "        rows_cols = [board_label_to_row_col(cell) for cell in cells]\n",
    "        index = tuple(zip(*rows_cols))\n",
    "\n",
    "        # Compute the state of orig and new board\n",
    "        new_board_state = move_sequence_to_state(tokens_to_board(moves_new), mode=\"normal\")[0, -1]\n",
    "        orig_board_state = move_sequence_to_state(tokens_to_board(moves_orig), mode=\"normal\")[0, -1]\n",
    "        # Put the cells of the new board in the orig board\n",
    "        orig_board_state[index] = new_board_state[index]\n",
    "\n",
    "        valid_cells = valid_moves_from_board(orig_board_state, moves_orig.shape[1])\n",
    "        new_valid_moves = one_hot(valid_cells).reshape(1, 1, 8, 8)\n",
    "\n",
    "    else:\n",
    "        new_valid_moves = move_sequence_to_state(tokens_to_board(moves_new), mode=\"valid\")\n",
    "\n",
    "    orig_logits = logits_to_board(model(moves_orig)[0, -1], \"log_prob\")\n",
    "    patched_logits = logits_to_board(patched_logits[0, -1], \"log_prob\")\n",
    "    new_logits = logits_to_board(new_logits[0, -1], \"log_prob\")\n",
    "\n",
    "    scale = new_logits.abs().max().cpu()\n",
    "\n",
    "    to_stack = [\n",
    "        orig_valid_moves[0, -1] * scale,\n",
    "        orig_logits,\n",
    "        patched_logits,\n",
    "        new_logits,\n",
    "        new_valid_moves[0, -1] * scale,\n",
    "        patched_logits - orig_logits,\n",
    "    ]\n",
    "\n",
    "    all_logits = t.stack([t.cpu() for t in to_stack], dim=-1)\n",
    "    plot_square_as_board(\n",
    "        all_logits,\n",
    "        title=\"Model predictions\",\n",
    "        facet_col=-1,\n",
    "        facet_col_wrap=3,\n",
    "        facet_labels=[\n",
    "            \"New expected\",\n",
    "            \"new logits\",\n",
    "            \"logit diff (patch - orig)\",\n",
    "            \"original expected\",\n",
    "            \"original logits\",\n",
    "            \"patched logits\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # plot_square_as_board(logits_to_board(new_logits[0, -1], 'log_prob'),\n",
    "    #                      title=\"Model predictions (new)\")\n",
    "    # plot_square_as_board(logits_to_board(patched_logits[0, -1], 'log_prob'),\n",
    "    #                      title=\"Model predictions (patched)\")\n",
    "\n",
    "    # with model.hooks(fwd_hooks=[(act_name, hook)]):\n",
    "    #     plot_board_log_probs(\n",
    "    #         tokens_to_board(moves_new[0]),\n",
    "    #         patched_logits[0],\n",
    "    #     )\n",
    "\n",
    "\n",
    "orig_index = 2\n",
    "new_index = 3\n",
    "move_index = 20\n",
    "layer = 4\n",
    "orig_games = focus_games_tokens[orig_index:orig_index + 1, :move_index]\n",
    "new_games = focus_games_tokens[new_index:new_index + 1, :move_index]\n",
    "\n",
    "modify_resid_given_probe(model, orig_games, new_games, *probes, layer=layer, cells=[\"D2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_board(focus_games_board_index[orig_index, :move_index], title=\"Original game\")\n",
    "plot_single_board(focus_games_board_index[new_index, :move_index], title=\"New game\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello-wfvDuSXh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
